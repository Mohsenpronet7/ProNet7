import requests
import base64
import jdatetime

# ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ Ù„ÛŒØ³Øª Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
with open("sources.txt", "r") as f:
    urls = [line.strip() for line in f if line.strip()]

all_configs = []

for url in urls:
    try:
        res = requests.get(url, timeout=20)
        if res.status_code == 200:
            decoded = base64.b64decode(res.text).decode("utf-8", errors="ignore")
            configs = [line.strip() for line in decoded.splitlines() if line.strip()]
            all_configs.extend(configs)
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª {url}: {e}")

# Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§
unique_configs = list(dict.fromkeys(all_configs))

# ØªØ§Ø±ÛŒØ® Ùˆ Ø³Ø§Ø¹Øª Ø´Ù…Ø³ÛŒ
now = jdatetime.datetime.now().strftime("%d %B %Y Ø³Ø§Ø¹Øª %H:%M")

# Ø³Ø§Ø®Øª Ù…ØªÙ† Ø®Ø±ÙˆØ¬ÛŒ
header = f"# Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ: {now}\n\n"
output = header + "\n".join(unique_configs)

# Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ txt
with open("output.txt", "w", encoding="utf-8") as f:
    f.write(output)

# Ø³Ø§Ø®Øª ÙØ§ÛŒÙ„ index.html Ø¨Ø±Ø§ÛŒ GitHub Pages
html_content = f"""
<html>
<head>
  <meta charset="utf-8">
  <title>Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ V2Ray</title>
</head>
<body style="font-family:tahoma;direction:rtl;margin:20px;">
  <h2>Ø¢Ø®Ø±ÛŒÙ† Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ</h2>
  <p>ğŸ“… {now} Ø¨Ù‡ ÙˆÙ‚Øª ØªÙ‡Ø±Ø§Ù†</p>
  <p>ğŸ”— ØªØ¹Ø¯Ø§Ø¯ Ø³Ø±ÙˆØ±Ù‡Ø§: {len(unique_configs)}</p>
  <p><a href="output.txt" download>Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ú©Ø§Ù…Ù„ (output.txt)</a></p>
  <hr>
  <textarea style="width:100%;height:400px;">{"\n".join(unique_configs)}</textarea>
</body>
</html>
"""

with open("index.html", "w", encoding="utf-8") as f:
    f.write(html_content)
